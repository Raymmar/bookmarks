import express from 'express';
import { Server } from 'http';

/**
 * Fake OpenAI server for testing.
 * 
 * This server is used to test services that interact with the OpenAI API.
 * 
 * Example usage:
 * 
 *     const openAiServer = new FakeOpenAiServer(3002);
 * 
 *     // Configure responses
 *     openAiServer.setEmbeddingResponse('test text', [0.1, 0.2, 0.3]);
 *     openAiServer.setChatCompletionResponse('test prompt', 'test response');
 * 
 *     // Start the server
 *     openAiServer.start();
 * 
 */
export class FakeOpenAiServer {
  private app: express.Application;
  private server: Server | null = null;
  private port: number;
  private embeddingResponses: Map<string, number[]> = new Map();
  private chatCompletionResponses: Map<string, ChatCompletionResponse> = new Map();

  constructor(port: number = 3002) {
    this.port = port;
    this.app = express();
    this.setupRoutes();
  }

  /**
   * The base URL of the fake OpenAI server. Use this to set the base URL for the OpenAI
   * client's config.
   */
  public get baseUrl(): string {
    return `http://localhost:${this.port}`;
  }

  private setupRoutes() {
    // Middleware to parse JSON bodies
    this.app.use(express.json());

    // Middleware to simulate authentication
    this.app.use((req, res, next) => {
      const authHeader = req.headers.authorization;
      if (!authHeader || !authHeader.startsWith('Bearer ')) {
        return res.status(401).json({ error: 'FakeOpenAIServer: Unauthorized' });
      }
      next();
    });

    // POST /embeddings
    this.app.post('/embeddings', (req, res) => {
      // console.log('FakeOpenAIServer: POST /embeddings', req.body);
      const { input } = req.body;

      if (!input) {
        return res.status(400).json({ error: 'FakeOpenAIServer: Input is required' });
      }

      // Get the embedding response for this input
      const embedding = this.embeddingResponses.get(input) || Array(1536).fill(0);

      const response = {
        object: 'list',
        data: [
          {
            object: 'embedding',
            embedding,
            index: 0,
          },
        ],
        model: 'text-embedding-ada-002',
        usage: {
          prompt_tokens: input.split(' ').length,
          total_tokens: input.split(' ').length,
        },
      };

      res.json(response);
    });

    // POST /vchat/completions
    this.app.post('/chat/completions', (req, res) => {
      // console.log('FakeOpenAIServer: POST /chat/completions', req.body);
      const { messages } = req.body;

      if (!messages || !Array.isArray(messages)) {
        return res.status(400).json({ error: 'FakeOpenAIServer: Messages array is required' });
      }

      // Get the last user message
      const lastUserMessage = messages.find(m => m.role === 'user')?.content || '';
      const completion: ChatCompletionResponse = this.chatCompletionResponses.get(lastUserMessage) || {
        summary: 'test summary',
        sentiment: 1,
        tags: [
          'tag-1',
          'tag-2',
          'tag-3',
        ],
      };

      // TODO: this response was generated by ChatGPT. Not sure if this response
      // format is 100% correct.
      const response = {
        id: 'chatcmpl-' + Math.random().toString(36).substring(7),
        object: 'chat.completion',
        created: Math.floor(Date.now() / 1000),
        model: 'gpt-4',
        choices: [
          {
            index: 0,
            message: {
              role: 'assistant',
              content: JSON.stringify(completion),
            },
            finish_reason: 'stop',
          },
        ],
        usage: {
          prompt_tokens: messages.reduce((acc, m) => acc + m.content.split(' ').length, 0),
          completion_tokens: completion.tags.length,
          total_tokens: messages.reduce((acc, m) => acc + m.content.split(' ').length, 0) + completion.tags.length,
        },
      };

      res.json(response);
    });
  }

  /**
   * Configures the embedding response for a given input text.
   * 
   * Example:
   * 
   *     setEmbeddingResponse('test text', [0.1, 0.2, 0.3]);
   */
  public setEmbeddingResponse(input: string, embedding: number[]) {
    this.embeddingResponses.set(input, embedding);
  }

  /**
   * Configures the chat completion response for a given prompt.
   * 
   * Example:
   * 
   *     setChatCompletionResponse('test prompt', {
   *       summary: 'test summary',
   *       sentiment: 0.5,
   *       tags: ['tag-1', 'tag-2', 'tag-3'],
   *     });
   */
  public setChatCompletionResponse(prompt: string, response: ChatCompletionResponse) {
    this.chatCompletionResponses.set(prompt, response);
  }

  // Method to start the server
  public start(): Promise<void> {
    return new Promise((resolve) => {
      this.server = this.app.listen(this.port, () => {
        console.log(`Fake OpenAI server running on port ${this.port}`);
        resolve();
      });
    });
  }

  // Method to stop the server
  public stop(): Promise<void> {
    return new Promise((resolve, reject) => {
      if (!this.server) {
        resolve();
        return;
      }

      this.server.close((err) => {
        if (err) {
          reject(err);
          return;
        }
        this.server = null;
        resolve();
      });
    });
  }

  // Method to clear all configured responses
  public clear() {
    this.embeddingResponses.clear();
    this.chatCompletionResponses.clear();
  }
} 

export interface ChatCompletionResponse {
  summary: string;
  sentiment: number;
  tags: string[];
}