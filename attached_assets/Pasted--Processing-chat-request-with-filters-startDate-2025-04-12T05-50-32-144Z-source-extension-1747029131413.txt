}
Processing chat request with filters: {"startDate":"2025-04-12T05:50:32.144Z","source":["extension","web","import","x"]} for user: c95a1d56-f721-4f9a-9104-7e4cf59caad7
5:50:32 AM [express] GET /api/chat/sessions/9426870d-dd3a-45c0-830b-1cf09d765cd1/messages 304 in 373…
Starting with 707 total bookmarks for user c95a1d56-f721-4f9a-9104-7e4cf59caad7
Filtering by start date: 2025-04-12T05:50:32.144Z
After start date filtering: 707 of 707 bookmarks remain
Filtering by sources: extension, web, import, x
After source filtering: 707 of 707 bookmarks remain
Limiting from 707 to 200 bookmarks to prevent context overflow
Sending 200 bookmarks to AI for context
First bookmark in context: "Hey @Replit please add an API to manage replits: list all (private &amp; public), get meta, dir s..."
Last bookmark in context: "This is a great quote by Michael Crichton, author of the Jurassic Park books, that came to my att..."
5:50:38 AM [express] GET /api/chat/sessions/06c54a6d-6154-4025-8de4-9ecec9c98636 200 in 306ms :: {"i…
5:50:38 AM [express] GET /api/chat/sessions/06c54a6d-6154-4025-8de4-9ecec9c98636/messages 200 in 305…
Error generating chat response: RateLimitError: 429 Request too large for gpt-4o in organization org-hCqzVQRM8O0p72PXepZhqTlT on tokens per min (TPM): Limit 30000, Requested 35407. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.
    at Function.generate (/home/runner/workspace/node_modules/openai/src/error.ts:96:14)
    at OpenAI.makeStatusError (/home/runner/workspace/node_modules/openai/src/core.ts:462:21)
    at OpenAI.makeRequest (/home/runner/workspace/node_modules/openai/src/core.ts:526:24)
    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)
    at async generateChatResponse (/home/runner/workspace/server/lib/content-processor.ts:791:22)
    at async <anonymous> (/home/runner/workspace/server/routes.ts:680:24) {
  status: 429,
  headers: {
    'alt-svc': 'h3=":443"; ma=86400',
    'cf-cache-status': 'DYNAMIC',
    'cf-ray': '93e7a3c8acf3dd19-ATL',
    connection: 'keep-alive',
    'content-length': '405',
    'content-type': 'application/json; charset=utf-8',
    date: 'Mon, 12 May 2025 05:50:39 GMT',
    server: 'cloudflare',
    'set-cookie': '__cf_bm=ieLlhJ8PZAqM7Dy9qEOeGwt.cKolBfGP_I482NRGELw-1747029039-1.0.1.1-NdnNNpa.BU6RPkZW4k378Ps7BdqpQ6Oc_w0UPRz81USQNpq.MAW0YFx4i83xm8OaY33ywE10nfyb8Zfo2bcwS6Ds3Dd3_.ydzSbCVgmTkWk; path=/; expires=Mon, 12-May-25 06:20:39 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None, _cfuvid=4UxoDfGMKrSQtmqEQYq5HP_uB_FSKAzx2wPwlBxsW5s-1747029039591-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None',
    'strict-transport-security': 'max-age=31536000; includeSubDomains; preload',
    vary: 'Origin',
    'x-content-type-options': 'nosniff',
    'x-ratelimit-limit-requests': '500',
    'x-ratelimit-limit-tokens': '30000',
    'x-ratelimit-remaining-requests': '499',
    'x-ratelimit-remaining-tokens': '30000',
    'x-ratelimit-reset-requests': '120ms',
    'x-ratelimit-reset-tokens': '0s',
    'x-request-id': 'req_6ce61966ff6e12ff11c8c0a4d2973c06'
  },
  request_id: 'req_6ce61966ff6e12ff11c8c0a4d2973c06',
  error: {
    message: 'Request too large for gpt-4o in organization org-hCqzVQRM8O0p72PXepZhqTlT on tokens per min (TPM): Limit 30000, Requested 35407. The input or output tokens must be reduced in order to run successfully. Visit https://platform.openai.com/account/rate-limits to learn more.',
    type: 'tokens',
    param: null,
    code: 'rate_limit_exceeded'
  },
  code: 'rate_limit_exceeded',
  param: null,
  type: 'tokens'